{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-25T15:50:58.842904Z",
     "start_time": "2024-11-25T15:50:55.255617Z"
    }
   },
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = keras.utils.text_dataset_from_directory( \n",
    "    '../../aclImdb/train/', \n",
    "    validation_split=0.2, \n",
    "    subset=\"training\", \n",
    "    seed=123,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = keras.utils.text_dataset_from_directory( \n",
    "    '../../aclImdb/train/', \n",
    "    validation_split=0.2, \n",
    "    subset=\"validation\", \n",
    "    seed=123, # same seed as above!\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = keras.utils.text_dataset_from_directory( \n",
    "    '../../aclImdb/test/', \n",
    "    batch_size=batch_size)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:51:09.110124Z",
     "start_time": "2024-11-25T15:51:03.873668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_tokens = 20000 # maximum vocabulary size \n",
    "max_length = 200 # maximum length of sequences\n",
    "\n",
    "vectorization_layer = keras.layers.TextVectorization( \n",
    "    max_tokens=max_tokens, \n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_length,\n",
    ")\n",
    "\n",
    "# Adapt the layer to the text data \n",
    "train_texts = train_ds.map(lambda x, y: x) \n",
    "vectorization_layer.adapt(train_texts)\n",
    "\n",
    "# Apply the vectorization to the datasets \n",
    "train_ds_int = train_ds.map(lambda x, y: (vectorization_layer(x), y)) \n",
    "val_ds_int = val_ds.map(lambda x, y: (vectorization_layer(x), y))\n",
    "test_ds_int = test_ds.map(lambda x, y: (vectorization_layer(x), y))"
   ],
   "id": "fb2234636d949219",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:51:10.889107Z",
     "start_time": "2024-11-25T15:51:10.817001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for (x, y) in train_ds_int.take(1):\n",
    "    print(x[0])\n",
    "    print(y[0])"
   ],
   "id": "6bb9ca2be65536f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 1582  2643  4133     8     4  9746   678     8    16   543    21    25\n",
      "   927   259     6    94   272     5    49   226    41   221  2138     4\n",
      "  3644  2209     8  5133     1     2     1  3725     6   702    41   561\n",
      "    21   288    34   312  7729  1307  9392    21     2  5741     5    25\n",
      "  7880     8     2 13496     5     2   319    19    15    28  2388     9\n",
      "  8661    46     5  1134    15    25  1312 13174    80  5528  7197  3720\n",
      "    15    45     9   146   174     6    27  3205    16     2   257     5\n",
      "   213     2  1349   131  1032     7  1676     8     2  5269     5  1980\n",
      "     1    13    11   319  2709  2210     2  1275     5     2    20    15\n",
      "    74    15  2097 17473  2422     6   161    46    87    28   841  1582\n",
      "  2643  6213     7    78    34  5207     5     2   403  2313     5     2\n",
      " 10814   596     6  2686   171     8     2  5269     5 16774     3     1\n",
      "    13     9     7    78   235     2   115    20   475    66     8     2\n",
      "   437    11   333    13    13    30    41    38  1544  2643   528     6\n",
      "  2224  5515     1    11   205    47  3700    64    11     7   145     3\n",
      "     8     2   301    23   206   255    89     2   385  9366    19  1285\n",
      "  5594   190    17    23     6    66   284     3], shape=(200,), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:51:16.469135Z",
     "start_time": "2024-11-25T15:51:16.462015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = ops.shape(inputs)[-1]\n",
    "        positions = ops.arange(start=0, stop=length, step=1)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        return embedded_tokens + embedded_positions\n"
   ],
   "id": "110b19a441f907e7",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:51:22.466673Z",
     "start_time": "2024-11-25T15:51:22.450532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation='relu'),\n",
    "             layers.Dense(embed_dim)])\n",
    "        self.layernorm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "    "
   ],
   "id": "d5c347c44259dfff",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:52:50.043416Z",
     "start_time": "2024-11-25T15:52:49.883138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = max_tokens\n",
    "sequence_length = max_length\n",
    "embed_dim = 32\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "\n",
    "inputs = layers.Input(shape=(max_length,))\n",
    "x = TokenAndPositionEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "id": "8ecae66d00669c53",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_9\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (\u001B[38;5;33mInputLayer\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ token_and_position_embedding_8  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │       \u001B[38;5;34m646,400\u001B[0m │\n",
       "│ (\u001B[38;5;33mTokenAndPositionEmbedding\u001B[0m)     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_4           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │        \u001B[38;5;34m10,656\u001B[0m │\n",
       "│ (\u001B[38;5;33mTransformerEncoder\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling1D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m33\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ token_and_position_embedding_8  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">646,400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,656</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m657,089\u001B[0m (2.51 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">657,089</span> (2.51 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m657,089\u001B[0m (2.51 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">657,089</span> (2.51 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:54:16.816988Z",
     "start_time": "2024-11-25T15:52:53.288520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    train_ds_int, batch_size=32, epochs=5, validation_data=(val_ds_int)\n",
    ")\n"
   ],
   "id": "d0bd0b59acca4b53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 22ms/step - accuracy: 0.6804 - loss: 0.5688 - val_accuracy: 0.8656 - val_loss: 0.3108\n",
      "Epoch 2/5\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 21ms/step - accuracy: 0.9063 - loss: 0.2429 - val_accuracy: 0.8694 - val_loss: 0.3391\n",
      "Epoch 3/5\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 22ms/step - accuracy: 0.9476 - loss: 0.1503 - val_accuracy: 0.8596 - val_loss: 0.4830\n",
      "Epoch 4/5\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 32ms/step - accuracy: 0.9701 - loss: 0.0863 - val_accuracy: 0.8532 - val_loss: 0.6247\n",
      "Epoch 5/5\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 33ms/step - accuracy: 0.9862 - loss: 0.0471 - val_accuracy: 0.8538 - val_loss: 0.7047\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:54:39.559920Z",
     "start_time": "2024-11-25T15:54:28.752967Z"
    }
   },
   "cell_type": "code",
   "source": "model.evaluate(test_ds_int)",
   "id": "f3c097972c6aea9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 14ms/step - accuracy: 0.8175 - loss: 0.8927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8746194243431091, 0.8207600116729736]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "97327e06fe283875"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
